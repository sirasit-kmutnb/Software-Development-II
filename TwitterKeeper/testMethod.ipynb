{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Twitter_keeper import PullTweetsData\n",
    "\n",
    "puller = PullTweetsData()\n",
    "\n",
    "test_cases = [\n",
    "            (\"Hello! Worldüåç https://www.example.com\", \"Hello/World\"),\n",
    "            (\"Hello üòÄ World üöÄüöÄhttps://www.example.com\", \"Hello/World\"),\n",
    "            (\"p https://www.example.com Hello World\", \"Hello/World\"),\n",
    "            (\"#‡∏ó‡∏£‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏ö‡∏î ‡∏•‡∏π‡∏Å‡∏™‡∏≤‡∏ß‡∏ä‡∏≠‡∏ö‡∏°‡∏≤‡∏Å‡∏ñ‡∏∂‡∏á‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡πá‡∏ö‡∏ã‡∏≠‡∏á‡πÄ‡∏•‡∏¢‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡πâ‡∏≤‡∏ô‡∏±‡πà‡∏á‡∏Å‡∏¥‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏≠‡∏û‡∏µ‡πà‡πÜpaper planes‡∏°‡∏≤ ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏≠‡∏µ‡∏Å‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÄ‡∏Ñ‡πâ‡∏≤‡∏à‡∏∞‡∏•‡∏∑‡∏°‡∏°‡∏±‡πâ‡∏¢ ‡πÅ‡∏ï‡πà‡∏Å‡πá‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡πâ‡∏≤‡∏Ç‡∏≠ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô ‡∏ñ‡πâ‡∏≤‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô‡∏Ñ‡∏∑‡∏≠‡πÅ‡∏£‡∏á‡∏ö‡∏±‡∏ô‡∏î‡∏≤‡∏•‡πÉ‡∏à‡πÉ‡∏´‡πâ‡∏•‡∏π‡∏Å‡πÄ‡∏£‡∏≤‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏î‡πá‡∏Å‡∏î‡∏µ‡∏Ñ‡∏ô‡∏î‡∏µ ‡πÅ‡∏°‡πà‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏£‡∏≤‡∏Å‡πá‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏≤‡∏Å‡πÜ‡∏ô‡∏∞ https://t.co/oWconpN1iP\", \"Hello/World\"),\n",
    "        ]\n",
    "for text, expected_output in test_cases:\n",
    "    print(puller.preprocessText(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Twitter_keeper import PullTweetsData\n",
    "from unittest.mock import MagicMock\n",
    "import pymongo\n",
    "# create a fake MongoClient\n",
    "fake_client = MagicMock(spec=pymongo.MongoClient)\n",
    "\n",
    "# create a fake database\n",
    "fake_db = MagicMock()\n",
    "fake_collection = MagicMock()\n",
    "# set the side effect for the fake MongoClient\n",
    "fake_client.__getitem__.side_effect = lambda x: fake_db\n",
    "fake_db.__getitem__.return_value = fake_collection\n",
    "# use the fake MongoClient in your code\n",
    "data_class = PullTweetsData()\n",
    "data_class.connectToDB(\"test_database\", \"test_collection\")\n",
    "data_class._PullTweetsData__db = fake_client\n",
    "\n",
    "# generate fake tweet data using fake-factory\n",
    "fake_tweet = {\n",
    "            \"tweet_create_at\": \"2022-01-01\",\n",
    "            \"tweet_author\": \"test1\",\n",
    "            \"tweet_content\": \"This is from test1\"\n",
    "        }\n",
    "\n",
    "# test the saveTweetsDict method\n",
    "data_class.saveTweetsDict(fake_tweet)\n",
    "\n",
    "# assert that the update_one method was called once\n",
    "assert fake_db.update_one.call_count == 1\n",
    "\n",
    "# assert that the update_one method was called with the expected arguments\n",
    "assert fake_db.update_one.call_args[0] == ({\"tweet_create_at\": fake_tweet[\"tweet_create_at\"], \"tweet_author\": fake_tweet[\"tweet_author\"]},)\n",
    "assert fake_db.update_one.call_args[1][\"$set\"] == fake_tweet\n",
    "assert fake_db.update_one.call_args[1][\"upsert\"] is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mongomock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from unittest.mock import MagicMock\n",
    "import pymongo\n",
    "from mongomock import MongoClient\n",
    "\n",
    "from Twitter_keeper import PullTweetsData\n",
    "\n",
    "Puller = PullTweetsData()\n",
    "mock_cli = MongoClient()\n",
    "mock_db = mock_cli['test_db']['test_col']\n",
    "Puller._PullTweetsData__db = mock_db\n",
    "\n",
    "tweet_post1 = {\"tweet_create_at\": \"2022-01-01 12:00:00\",\n",
    "                \"tweet_author\": \"test_author1\",\n",
    "                \"tweet_text\": \"test tweet1\"}\n",
    "\n",
    "tweet_post2 = {\"tweet_create_at\": \"2022-01-01 12:00:01\",\n",
    "                      \"tweet_author\": \"test_author1\",\n",
    "                      \"tweet_text\": \"test tweet2\"}\n",
    "\n",
    "Puller.saveTweetsDict(tweet_post=tweet_post1)\n",
    "Puller.saveTweetsDict(tweet_post=tweet_post1)\n",
    "Puller.saveTweetsDict(tweet_post=tweet_post2)\n",
    "\n",
    "saved_tw = mock_db.find({\n",
    "                \"tweet_author\": \"test_author1\"})\n",
    "print((saved_tw))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sched\n",
    "from threading import Thread\n",
    "from threading import Lock\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import emoji\n",
    "import re\n",
    "import pymongo\n",
    "from datetime import datetime, timezone\n",
    "from dateutil import tz\n",
    "import pytz\n",
    "from termcolor import colored\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp import sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Twitter_keeper import PullTweetsData\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import emoji\n",
    "import numpy as np\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "import pandas as pd\n",
    "\n",
    "class FindTopWord(PullTweetsData):\n",
    "\n",
    "    def tokenize(self,d):  \n",
    "        result = d.split(\"/\")\n",
    "        result = list(filter(None, result))\n",
    "        return result\n",
    "\n",
    "    def prepared_Text(self,text_list):\n",
    "        new_text = []\n",
    "        for text in text_list:\n",
    "            new_text.append(self.preprocessText(text))\n",
    "        return new_text\n",
    "        \n",
    "    def MostWordFinder(self,tweets_list):\n",
    "        vectorizer = CountVectorizer(tokenizer=self.tokenize)\n",
    "        transformed_data = vectorizer.fit_transform(tweets_list)\n",
    "        keyword_df1 = pd.DataFrame(columns = ['word', 'count'])\n",
    "        keyword_df1['word'] = vectorizer.get_feature_names_out()\n",
    "        print(vectorizer.get_feature_names_out())\n",
    "        keyword_df1['count'] = np.ravel(transformed_data.sum(axis=0))   \n",
    "        keyword_df1.sort_values(by=['count'], ascending=False).head(10)\n",
    "        return keyword_df1\n",
    "\n",
    "\n",
    "\n",
    "class SentimentAnalyze(PullTweetsData):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__df_train = pd.read_csv(\"general-amy.csv\")\n",
    "        self.__vectorizer = CountVectorizer()\n",
    "        self.__model = MultinomialNB()\n",
    "\n",
    "    def preprocess_train_text(self,text):\n",
    "        text = self.removeLink(text)\n",
    "        text = self.removeEmoji(text)\n",
    "        text = self.removeSpecialChar(text)\n",
    "        final = \"\".join(u for u in text if u not in (\"?\", \".\", \";\", \":\", \"!\", '\"', \"‡πÜ\", \"‡∏Ø\"))\n",
    "        final = word_tokenize(final, engine=\"newmm\")\n",
    "        final = \" \".join(word for word in final)\n",
    "        # final = \" \".join(word for word in final.split() if word.lower not in thai_stopwords())\n",
    "        return final\n",
    "        # tokens = word_tokenize(text, engine=\"newmm\")\n",
    "        # result = [word for word in tokens if word not in list(\n",
    "        #         thai_stopwords()) and \" \" not in word]\n",
    "        # return \" \".join(result).rstrip()\n",
    "\n",
    "    def run_prep_train(self):\n",
    "        self.__df_train['text'] = self.__df_train['text'].apply(self.preprocess_train_text)\n",
    "\n",
    "    def split_training(self):\n",
    "        self.X = self.__vectorizer.fit_transform(self.__df_train['text'])\n",
    "        self.y = self.__df_train['sentiment']\n",
    "        # Split the data into training and testing sets\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2)\n",
    "\n",
    "    def training_model(self):\n",
    "        self.run_prep_train()\n",
    "        self.split_training()\n",
    "        # Train the model\n",
    "        self.__model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def evaluating_model(self):\n",
    "        #Evaluate the model on the test data\n",
    "        y_pred = self.__model.predict(self.X_test)\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        return accuracy\n",
    "\n",
    "    def sentiment_analyzer(self,text):\n",
    "        #Use the model to make predictions on new data\n",
    "        new_text = self.__vectorizer.transform([text])\n",
    "        new_bag_of_word = self.__vectorizer.transform(pd.Series([self.preprocess_train_text(text)]))\n",
    "        # print(new_bag_of_word)\n",
    "        new_pred = self.__model.predict(new_bag_of_word)\n",
    "        return new_pred[0]\n",
    "\n",
    "class main(PullTweetsData):\n",
    "    def __init__(self):\n",
    "        self.find_top_word = FindTopWord()\n",
    "        self.sentiment_analyze = SentimentAnalyze()\n",
    "\n",
    "    def load_sample_tweets(self,keyword):\n",
    "        self.connectToDB(\"twitter\",\"tweets\")\n",
    "        return self.find_tweets(\"keyword\",keyword,\"return\")\n",
    "\n",
    "    def tweets_find_top_word(self,keyword):\n",
    "        tweets_list = self.prepared_Text(self.load_sample_tweets(keyword))\n",
    "        return self.find_top_word.MostWordFinder(tweets_list)\n",
    "\n",
    "    def tweets_sentiment_analyzer(self,keyword):\n",
    "        self.sentiment_analyze.training_model()\n",
    "        acc = self.sentiment_analyze.evaluating_model()\n",
    "        tweets_list = self.load_sample_tweets(keyword)\n",
    "        df = pd.DataFrame({'text':[],'sentiment':[]})\n",
    "        for tweet in tqdm(tweets_list):\n",
    "            sentiment = self.sentiment_analyze.sentiment_analyzer(tweet)\n",
    "            df = pd.concat([df,pd.DataFrame(pd.Series([tweet,sentiment], index=df.columns)).T],ignore_index=True)\n",
    "        return df\n",
    "\n",
    "TweetsCounter = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5042/5042 [00:04<00:00, 1161.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡∏ó‡∏≥‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡πÄ‡∏¢‡∏≠‡∏∞ + ‡∏Ç‡∏≥‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö + ‡∏ô‡∏≠‡∏ô‡∏£‡∏≠‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏•‡∏¥‡∏Å =...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡∏ô‡πâ‡∏≥‡πÄ‡∏õ‡∏•‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏ô‡πâ‡∏≥‡πÄ‡πÄ‡∏£‡πà‡∏°‡∏∂‡∏á‡∏Å‡πá‡πÄ‡πÄ‡∏î‡∏Å‡πÜ‡πÑ‡∏õ‡πÄ‡∏ñ‡∏≠‡∏∞‡∏Ñ‡πà‡∏∞ ‡∏≠‡∏¢‡πà‡∏≤‡πÄ‡∏£‡∏∑...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡∏´‡∏°‡∏≤‡∏õ‡∏π‡πà‡∏à‡∏≠‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡πâ‡∏≥‡πÄ‡∏¢‡πá‡∏ô.... \\n‡∏Å‡∏π‡∏ó‡∏µ‡πà‡∏ô‡∏∂‡∏Å‡∏ß‡πà‡∏≤‡∏•‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏ô‡∏Å...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï‡∏ü‡∏£‡∏µ 100 ‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡πÉ‡∏´‡∏°‡πà\\n‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏Å‡∏îüëâhttps://t.co...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"‡∏ô‡πâ‡∏≥‡πÄ‡∏õ‡∏•‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏ô‡πâ‡∏≥‡πÅ‡∏£‡πà ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∞‡πÑ‡∏£\"#Onet66 https://t...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5037</th>\n",
       "      <td>‡∏Ç‡πâ‡∏≠‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå‡∏Å‡∏π‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö6‡πÇ‡∏°‡∏á‡πÄ‡∏ä‡πâ‡∏≤‡πÅ‡∏ï‡πàgoogle‡∏ï‡∏≠‡∏ö‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏á...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5038</th>\n",
       "      <td>‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏∏‡∏ï‡∏≠‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡∏ö‡∏ó‡∏à‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡∏´‡∏°‡∏≤‡πÄ‡∏¢‡πá‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à  #Onet66 htt...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>‡πÑ‡∏î‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÇ‡∏≠‡πÄ‡∏ô‡πâ‡∏ï50+++ ‡∏ó‡∏∏‡∏Å‡∏ß‡∏¥‡∏ä‡∏≤ ‡∏™‡∏∏‡πà‡∏°‡πÅ‡∏à‡∏Å100‡∏ö‡∏≤‡∏ó 2‡∏Ñ‡∏ôüòã...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>‡∏ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ‡πÑ‡∏ó‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô 90 ‡πÅ‡∏à‡∏Å 100 #Onet66</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5041</th>\n",
       "      <td>‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÄ‡∏ï‡πá‡∏°‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏à‡∏Å100‡∏ø#Onet66</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5042 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment\n",
       "0     ‡∏ó‡∏≥‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡πÄ‡∏¢‡∏≠‡∏∞ + ‡∏Ç‡∏≥‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö + ‡∏ô‡∏≠‡∏ô‡∏£‡∏≠‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏•‡∏¥‡∏Å =...       neg\n",
       "1     ‡∏ô‡πâ‡∏≥‡πÄ‡∏õ‡∏•‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏ô‡πâ‡∏≥‡πÄ‡πÄ‡∏£‡πà‡∏°‡∏∂‡∏á‡∏Å‡πá‡πÄ‡πÄ‡∏î‡∏Å‡πÜ‡πÑ‡∏õ‡πÄ‡∏ñ‡∏≠‡∏∞‡∏Ñ‡πà‡∏∞ ‡∏≠‡∏¢‡πà‡∏≤‡πÄ‡∏£‡∏∑...       neg\n",
       "2     ‡∏´‡∏°‡∏≤‡∏õ‡∏π‡πà‡∏à‡∏≠‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡πâ‡∏≥‡πÄ‡∏¢‡πá‡∏ô.... \\n‡∏Å‡∏π‡∏ó‡∏µ‡πà‡∏ô‡∏∂‡∏Å‡∏ß‡πà‡∏≤‡∏•‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏ô‡∏Å...       neg\n",
       "3     ‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï‡∏ü‡∏£‡∏µ 100 ‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡πÉ‡∏´‡∏°‡πà\\n‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏Å‡∏îüëâhttps://t.co...       neg\n",
       "4     \"‡∏ô‡πâ‡∏≥‡πÄ‡∏õ‡∏•‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏ô‡πâ‡∏≥‡πÅ‡∏£‡πà ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∞‡πÑ‡∏£\"#Onet66 https://t...       pos\n",
       "...                                                 ...       ...\n",
       "5037  ‡∏Ç‡πâ‡∏≠‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå‡∏Å‡∏π‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö6‡πÇ‡∏°‡∏á‡πÄ‡∏ä‡πâ‡∏≤‡πÅ‡∏ï‡πàgoogle‡∏ï‡∏≠‡∏ö‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏á...       neg\n",
       "5038  ‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏∏‡∏ï‡∏≠‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡∏ö‡∏ó‡∏à‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡∏´‡∏°‡∏≤‡πÄ‡∏¢‡πá‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à  #Onet66 htt...       pos\n",
       "5039  ‡πÑ‡∏î‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÇ‡∏≠‡πÄ‡∏ô‡πâ‡∏ï50+++ ‡∏ó‡∏∏‡∏Å‡∏ß‡∏¥‡∏ä‡∏≤ ‡∏™‡∏∏‡πà‡∏°‡πÅ‡∏à‡∏Å100‡∏ö‡∏≤‡∏ó 2‡∏Ñ‡∏ôüòã...       neg\n",
       "5040                   ‡∏ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ‡πÑ‡∏ó‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô 90 ‡πÅ‡∏à‡∏Å 100 #Onet66       neg\n",
       "5041                  ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÄ‡∏ï‡πá‡∏°‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏à‡∏Å100‡∏ø#Onet66       neg\n",
       "\n",
       "[5042 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display,HTML\n",
    "\n",
    "df = TweetsCounter.tweets_sentiment_analyzer(\"#Onet66\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg    3566\n",
      "pos    1476\n",
      "Name: sentiment, dtype: int64\n",
      "neg    70.725902\n",
      "pos    29.274098\n",
      "Name: sentiment, dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "hovertemplate": "index=%{label}<br>value=%{value}<extra></extra>",
         "labels": [
          "neg",
          "pos"
         ],
         "legendgroup": "",
         "name": "",
         "showlegend": true,
         "type": "pie",
         "values": [
          70.72590241967474,
          29.27409758032527
         ]
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Sentiment Percentage"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Count the number of occurrences of each sentiment\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "\n",
    "print(sentiment_counts)\n",
    "# Calculate the percentage of each sentiment\n",
    "sentiment_percentages = sentiment_counts / len(df) * 100\n",
    "print(sentiment_percentages)\n",
    "# Create the pie chart\n",
    "fig = px.pie(sentiment_percentages, values=sentiment_percentages.values, \n",
    "             names=sentiment_percentages.index, title='Sentiment Percentage')\n",
    "\n",
    "# Show the chart\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TweetsCounter.tweets_sentiment_analyzer(\"#‡πÉ‡∏™‡πà‡∏ô‡∏±‡∏ß‡πÅ‡∏ü‡∏°‡∏¥‡∏•‡∏µ‡πà\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"general-amy.csv\")\n",
    "print(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import emoji\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "\n",
    "def removeSpecialChar(text):\n",
    "    return re.sub(r\"[\\]\\[!-@#$?%+:\\\"\\n^_‚Äò‚Äô‚Äú‚Äù]\", \"\", text).rstrip()\n",
    "\n",
    "def removeEmoji(text):\n",
    "    allchars = [str for str in text]\n",
    "    emoji_list = [c for c in allchars if c in emoji.EMOJI_DATA]\n",
    "    return ''.join([str for str in allchars if not any(i in str for i in emoji_list)]).rstrip()\n",
    "\n",
    "def removeLink(text):\n",
    "    new_text = re.sub(r'https?:\\/\\/[^\\s]+', '', text)\n",
    "    # text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE).rstrip()\n",
    "    link_regex = r\"(https?:\\/\\/[-a-zA-Z0-9@:%._\\+~#=]+)\"\n",
    "    return re.sub(link_regex, '', new_text).rstrip().lstrip()\n",
    "\n",
    "# Pre-processing the data\n",
    "def preprocess_train_text(text):\n",
    "    text = removeLink(text)\n",
    "    text = removeEmoji(text)\n",
    "    text = removeSpecialChar(text)\n",
    "    tokens = word_tokenize(text, engine=\"newmm\")\n",
    "    result = [word for word in tokens if word not in list(\n",
    "            thai_stopwords()) and \" \" not in word]\n",
    "    return \" \".join(result).rstrip()\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(preprocess_train_text)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['sentiment']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train the model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate the model on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#Use the model to make predictions on new data\n",
    "new_text = ['''‡πÄ‡∏£‡∏≤‡∏ä‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡πâ‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏±‡∏á ü•π Cr ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡πÄ‡∏û‡∏à IHaveCPU #hrk #heartrocker #‡πÉ‡∏™‡πà‡∏ô‡∏±‡∏ß‡πÅ‡∏ü‡∏°‡∏¥‡∏•‡∏µ‡πà https://t.co/7QHIs4fYsd''']\n",
    "new_text = vectorizer.transform(new_text)\n",
    "new_pred = model.predict(new_text)\n",
    "print(\"Sentiment:\", new_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "from dotenv import load_dotenv\n",
    "from dateutil import tz\n",
    "import tweepy\n",
    "\n",
    "API_KEY = \"SnxucIPt1fg7UUyVOT0T5j0pR\"\n",
    "API_KEY_SECRET = \"yaToQPv95OA1fiNTHD8drKM8g8rZGM7jSQnPOLoxU3QA9UpaLm\"\n",
    "ACCESS_TOKEN = \"1722424471-Xb0DjPVOqXsLj2sXEYXmU2sqxaDC4B793erGO6J\"\n",
    "ACCESS_TOKEN_SECRET = \"D2LyXN11zAoZB0M476eb1ZGDM55oRvy4tBWNb8pR4CO0h\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(API_KEY, API_KEY_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "count = 0\n",
    "def getHashtag(entity_hashtag):\n",
    "        hashtag = \"\"\n",
    "        for i in range(0, len(entity_hashtag)):\n",
    "            hashtag = hashtag + \"#\"+entity_hashtag[i][\"text\"]\n",
    "        return hashtag\n",
    "def createDictData(tweet_author, tweet_create_at, hashtag, keyword, text):\n",
    "        tweet = {}\n",
    "        tweet[\"tweet_author\"] = tweet_author\n",
    "        tweet[\"tweet_create_at\"] = tweet_create_at\n",
    "        tweet[\"hashtag\"] = hashtag\n",
    "        tweet[\"keyword\"] = keyword\n",
    "        tweet[\"text\"] = text\n",
    "        return tweet\n",
    "amount = 10\n",
    "query = \"#Valorant\"\n",
    "for tweet in tqdm(tweepy.Cursor(api.search_tweets, q=query, count=100,\n",
    "                                        result_type=\"recent\", tweet_mode='extended').items()):\n",
    "    entity_hashtag = tweet.entities.get('hashtags')\n",
    "    hashtag = getHashtag(entity_hashtag)\n",
    "    tweet_author = tweet.user.screen_name\n",
    "    keyword = query\n",
    "    dt_str = str(tweet.created_at)\n",
    "    format = \"%Y-%m-%d %H:%M:%S%z\"\n",
    "    dt_utc = datetime.strptime(dt_str, format)\n",
    "    local_zone = tz.tzlocal()\n",
    "    dt_local = dt_utc.astimezone(local_zone)\n",
    "    tweet_create_at = dt_local\n",
    "    try:\n",
    "        text = tweet.retweeted_status.full_text\n",
    "    except:\n",
    "        text = tweet.full_text\n",
    "    user = tweet.user\n",
    "    location = user.location\n",
    "    print(user.screen_name,location)\n",
    "    count += 1\n",
    "    if count == amount:\n",
    "        count = 0\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e0abb541ba73b2fefa88a1c6ccc4fc6cb74c7244aedb0a4b700917b360d939c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
