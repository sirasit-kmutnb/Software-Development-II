{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Twitter_keeper import PullTweetsData\n",
    "\n",
    "puller = PullTweetsData()\n",
    "\n",
    "test_cases = [\n",
    "            (\"Hello! Worldüåç https://www.example.com\", \"Hello/World\"),\n",
    "            (\"Hello üòÄ World üöÄüöÄhttps://www.example.com\", \"Hello/World\"),\n",
    "            (\"p https://www.example.com Hello World\", \"Hello/World\"),\n",
    "            (\"#‡∏ó‡∏£‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏ö‡∏î ‡∏•‡∏π‡∏Å‡∏™‡∏≤‡∏ß‡∏ä‡∏≠‡∏ö‡∏°‡∏≤‡∏Å‡∏ñ‡∏∂‡∏á‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡πá‡∏ö‡∏ã‡∏≠‡∏á‡πÄ‡∏•‡∏¢‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡πâ‡∏≤‡∏ô‡∏±‡πà‡∏á‡∏Å‡∏¥‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏≠‡∏û‡∏µ‡πà‡πÜpaper planes‡∏°‡∏≤ ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏≠‡∏µ‡∏Å‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÄ‡∏Ñ‡πâ‡∏≤‡∏à‡∏∞‡∏•‡∏∑‡∏°‡∏°‡∏±‡πâ‡∏¢ ‡πÅ‡∏ï‡πà‡∏Å‡πá‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡πâ‡∏≤‡∏Ç‡∏≠ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô ‡∏ñ‡πâ‡∏≤‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô‡∏Ñ‡∏∑‡∏≠‡πÅ‡∏£‡∏á‡∏ö‡∏±‡∏ô‡∏î‡∏≤‡∏•‡πÉ‡∏à‡πÉ‡∏´‡πâ‡∏•‡∏π‡∏Å‡πÄ‡∏£‡∏≤‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏î‡πá‡∏Å‡∏î‡∏µ‡∏Ñ‡∏ô‡∏î‡∏µ ‡πÅ‡∏°‡πà‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏£‡∏≤‡∏Å‡πá‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏≤‡∏Å‡πÜ‡∏ô‡∏∞ https://t.co/oWconpN1iP\", \"Hello/World\"),\n",
    "        ]\n",
    "for text, expected_output in test_cases:\n",
    "    print(puller.preprocessText(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Twitter_keeper import PullTweetsData\n",
    "from unittest.mock import MagicMock\n",
    "import pymongo\n",
    "# create a fake MongoClient\n",
    "fake_client = MagicMock(spec=pymongo.MongoClient)\n",
    "\n",
    "# create a fake database\n",
    "fake_db = MagicMock()\n",
    "fake_collection = MagicMock()\n",
    "# set the side effect for the fake MongoClient\n",
    "fake_client.__getitem__.side_effect = lambda x: fake_db\n",
    "fake_db.__getitem__.return_value = fake_collection\n",
    "# use the fake MongoClient in your code\n",
    "data_class = PullTweetsData()\n",
    "data_class.connectToDB(\"test_database\", \"test_collection\")\n",
    "data_class._PullTweetsData__db = fake_client\n",
    "\n",
    "# generate fake tweet data using fake-factory\n",
    "fake_tweet = {\n",
    "            \"tweet_create_at\": \"2022-01-01\",\n",
    "            \"tweet_author\": \"test1\",\n",
    "            \"tweet_content\": \"This is from test1\"\n",
    "        }\n",
    "\n",
    "# test the saveTweetsDict method\n",
    "data_class.saveTweetsDict(fake_tweet)\n",
    "\n",
    "# assert that the update_one method was called once\n",
    "assert fake_db.update_one.call_count == 1\n",
    "\n",
    "# assert that the update_one method was called with the expected arguments\n",
    "assert fake_db.update_one.call_args[0] == ({\"tweet_create_at\": fake_tweet[\"tweet_create_at\"], \"tweet_author\": fake_tweet[\"tweet_author\"]},)\n",
    "assert fake_db.update_one.call_args[1][\"$set\"] == fake_tweet\n",
    "assert fake_db.update_one.call_args[1][\"upsert\"] is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mongomock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from unittest.mock import MagicMock\n",
    "import pymongo\n",
    "from mongomock import MongoClient\n",
    "\n",
    "from Twitter_keeper import PullTweetsData\n",
    "\n",
    "Puller = PullTweetsData()\n",
    "mock_cli = MongoClient()\n",
    "mock_db = mock_cli['test_db']['test_col']\n",
    "Puller._PullTweetsData__db = mock_db\n",
    "\n",
    "tweet_post1 = {\"tweet_create_at\": \"2022-01-01 12:00:00\",\n",
    "                \"tweet_author\": \"test_author1\",\n",
    "                \"tweet_text\": \"test tweet1\"}\n",
    "\n",
    "tweet_post2 = {\"tweet_create_at\": \"2022-01-01 12:00:01\",\n",
    "                      \"tweet_author\": \"test_author1\",\n",
    "                      \"tweet_text\": \"test tweet2\"}\n",
    "\n",
    "Puller.saveTweetsDict(tweet_post=tweet_post1)\n",
    "Puller.saveTweetsDict(tweet_post=tweet_post1)\n",
    "Puller.saveTweetsDict(tweet_post=tweet_post2)\n",
    "\n",
    "saved_tw = mock_db.find({\n",
    "                \"tweet_author\": \"test_author1\"})\n",
    "print((saved_tw))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sched\n",
    "from threading import Thread\n",
    "from threading import Lock\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import emoji\n",
    "import re\n",
    "import pymongo\n",
    "from datetime import datetime, timezone\n",
    "from dateutil import tz\n",
    "import pytz\n",
    "from termcolor import colored\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp import sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Twitter_keeper import PullTweetsData\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import emoji\n",
    "import numpy as np\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "import pandas as pd\n",
    "\n",
    "class FindTopWord(PullTweetsData):\n",
    "\n",
    "    def tokenize(self,d):  \n",
    "        result = d.split(\"/\")\n",
    "        result = list(filter(None, result))\n",
    "        return result\n",
    "\n",
    "    def prepared_Text(self,text_list):\n",
    "        new_text = []\n",
    "        for text in text_list:\n",
    "            new_text.append(self.preprocessText(text))\n",
    "        return new_text\n",
    "        \n",
    "    def MostWordFinder(self,tweets_list):\n",
    "        vectorizer = CountVectorizer(tokenizer=self.tokenize)\n",
    "        transformed_data = vectorizer.fit_transform(tweets_list)\n",
    "        keyword_df1 = pd.DataFrame(columns = ['word', 'count'])\n",
    "        keyword_df1['word'] = vectorizer.get_feature_names_out()\n",
    "        print(vectorizer.get_feature_names_out())\n",
    "        keyword_df1['count'] = np.ravel(transformed_data.sum(axis=0))   \n",
    "        keyword_df1.sort_values(by=['count'], ascending=False).head(10)\n",
    "        return keyword_df1\n",
    "\n",
    "\n",
    "\n",
    "class SentimentAnalyze(PullTweetsData):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__df_train = pd.read_csv(\"general-amy.csv\")\n",
    "        self.__vectorizer = CountVectorizer()\n",
    "        self.__model = MultinomialNB()\n",
    "\n",
    "    def preprocess_train_text(self,text):\n",
    "        text = self.removeLink(text)\n",
    "        text = self.removeEmoji(text)\n",
    "        text = self.removeSpecialChar(text)\n",
    "        final = \"\".join(u for u in text if u not in (\"?\", \".\", \";\", \":\", \"!\", '\"', \"‡πÜ\", \"‡∏Ø\"))\n",
    "        final = word_tokenize(final, engine=\"newmm\")\n",
    "        final = \" \".join(word for word in final)\n",
    "        # final = \" \".join(word for word in final.split() if word.lower not in thai_stopwords())\n",
    "        return final\n",
    "        # tokens = word_tokenize(text, engine=\"newmm\")\n",
    "        # result = [word for word in tokens if word not in list(\n",
    "        #         thai_stopwords()) and \" \" not in word]\n",
    "        # return \" \".join(result).rstrip()\n",
    "\n",
    "    def run_prep_train(self):\n",
    "        self.__df_train['text'] = self.__df_train['text'].apply(self.preprocess_train_text)\n",
    "\n",
    "    def split_training(self):\n",
    "        self.X = self.__vectorizer.fit_transform(self.__df_train['text'])\n",
    "        self.y = self.__df_train['sentiment']\n",
    "        # Split the data into training and testing sets\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2)\n",
    "\n",
    "    def training_model(self):\n",
    "        self.run_prep_train()\n",
    "        self.split_training()\n",
    "        # Train the model\n",
    "        self.__model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def evaluating_model(self):\n",
    "        #Evaluate the model on the test data\n",
    "        y_pred = self.__model.predict(self.X_test)\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        return accuracy\n",
    "\n",
    "    def sentiment_analyzer(self,text):\n",
    "        #Use the model to make predictions on new data\n",
    "        new_text = self.__vectorizer.transform([text])\n",
    "        new_bag_of_word = self.__vectorizer.transform(pd.Series([self.preprocess_train_text(text)]))\n",
    "        # print(new_bag_of_word)\n",
    "        new_pred = self.__model.predict(new_bag_of_word)\n",
    "        return new_pred[0]\n",
    "\n",
    "class main(PullTweetsData):\n",
    "    def __init__(self):\n",
    "        self.find_top_word = FindTopWord()\n",
    "        self.sentiment_analyze = SentimentAnalyze()\n",
    "        self.pull_tweets = PullTweetsData()\n",
    "\n",
    "    def load_sample_tweets(self,author=\"\",keyword=\"\",hashtag=\"\",location=\"\",text=\"\",fromTime=\"\",toTime=\"\"):\n",
    "        self.pull_tweets.connectToDB(\"twitter_keeper\",\"tweets\")\n",
    "        return self.pull_tweets.find_multi(author,keyword,hashtag,location,text,fromTime,toTime)\n",
    "\n",
    "    def tweets_find_top_word(self,author=\"\",keyword=\"\",hashtag=\"\",location=\"\",text=\"\",fromTime=\"\",toTime=\"\"):\n",
    "        tweets_list = self.prepared_Text(self.load_sample_tweets(author,keyword,hashtag,location,text,fromTime,toTime))\n",
    "        return self.find_top_word.MostWordFinder(tweets_list)\n",
    "\n",
    "    def tweets_sentiment_analyzer(self,author=\"\",keyword=\"\",hashtag=\"\",location=\"\",text=\"\",fromTime=\"\",toTime=\"\"):\n",
    "        self.sentiment_analyze.training_model()\n",
    "        acc = self.sentiment_analyze.evaluating_model()\n",
    "        tweets_list = self.load_sample_tweets(author,keyword,hashtag,location,text,fromTime,toTime)\n",
    "        df = pd.DataFrame({'text':[],'sentiment':[]})\n",
    "        for tweet in tqdm(tweets_list):\n",
    "            sentiment = self.sentiment_analyze.sentiment_analyzer(tweet['text'])\n",
    "            df = pd.concat([df,pd.DataFrame(pd.Series([tweet['text'],sentiment], index=df.columns)).T],ignore_index=True)\n",
    "        return df\n",
    "\n",
    "TweetsCounter = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TweetsCounter.load_sample_tweets(keyword=\"#Onet66\",fromTime=\"2023.2.13.3.53.53\",toTime=\"2024.2.13.3.53.53\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2023, 2, 13, 3, 53, 53]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TweetsCounter.splittime(\"2023.2.13.3.53.53\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TweetsCounter.find_multi(\"\",\"\",\"\",\"Bangkok\",\"\",\"2023.2.13.3.24.45\",\"2024.2.13.3.24.45\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6316/6316 [00:03<00:00, 1865.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üîÆ‡∏Ñ‡∏≤‡∏ñ‡∏≤‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏ö‡∏ú‡πà‡∏≤‡∏ôüîÆ\\n‡∏ï‡∏±‡πâ‡∏á ‡∏ô‡∏∞‡πÇ‡∏° ‡∏ï‡∏±‡∏™‡∏™‡∏∞ ‡∏†‡∏∞‡∏Ñ‡∏∞‡∏ß‡∏∞‡πÇ‡∏ï ‡∏≠...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üîÆ‡∏Ñ‡∏≤‡∏ñ‡∏≤‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏ö‡∏ú‡πà‡∏≤‡∏ôüîÆ\\n‡∏ï‡∏±‡πâ‡∏á ‡∏ô‡∏∞‡πÇ‡∏° ‡∏ï‡∏±‡∏™‡∏™‡∏∞ ‡∏†‡∏∞‡∏Ñ‡∏∞‡∏ß‡∏∞‡πÇ‡∏ï ‡∏≠...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üí°‡∏£‡∏≤‡∏®‡∏µ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏î‡∏ß‡∏á‡∏à‡∏∞‡∏™‡∏°‡∏´‡∏ß‡∏±‡∏á‡πÉ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏Åüí°\\n‚úÖ‡∏û‡∏§‡∏©‡∏†\\n‚úÖ‡∏°‡∏±‡∏á‡∏Å‡∏£...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏Ñ‡πà‡∏∞ #‡∏î‡∏π‡πÑ‡∏û‡πà‡∏Å‡∏±‡∏öoctsy\\n\\n‡∏£‡∏µ‡∏ß‡∏¥‡∏ß ‡∏î‡∏π‡∏î‡∏ß‡∏á‡πÑ‡∏û‡πà üôè\\n\\...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡∏Ñ‡∏¥‡∏ß‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏±‡∏Å DM ‡πÄ‡∏•‡∏¢   \\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡∏∞32‡∏ø\\nü•π‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏â‡∏û‡∏≤...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6311</th>\n",
       "      <td>‡∏ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏ß‡∏¥‡∏ó ‡∏Ñ‡∏∫‡∏ì‡∏¥‡∏ï ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ \\n 50+/100   ‡πÅ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6312</th>\n",
       "      <td>‡∏ß‡∏¥‡∏ó‡∏¢‡πå‡∏Å‡∏±‡∏ö‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ50+ ‡πÅ‡∏à‡∏Å50/1 ‡∏Ñ‡∏ô ‡∏£‡∏µ‡∏¢‡∏≤‡∏ß‡πÜ55 #O...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6313</th>\n",
       "      <td>‡∏ó‡∏∏‡∏Å‡∏ß‡∏¥‡∏ä‡∏≤50++ ‡πÅ‡∏à‡∏Å 50‡∏ö./1 ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©/‡πÑ‡∏ó‡∏¢ 80++ ‡πÅ‡∏à‡∏Å‡∏≠‡∏µ‡∏Å ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6314</th>\n",
       "      <td>‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÑ‡∏î‡πâ50+++ ‡πÅ‡∏à‡∏Å100 #Onet66</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6315</th>\n",
       "      <td>&amp;gt;&amp;gt; ‡∏î‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 13 ‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå 2566 &amp;lt;&amp;lt;...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6316 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment\n",
       "0     üîÆ‡∏Ñ‡∏≤‡∏ñ‡∏≤‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏ö‡∏ú‡πà‡∏≤‡∏ôüîÆ\\n‡∏ï‡∏±‡πâ‡∏á ‡∏ô‡∏∞‡πÇ‡∏° ‡∏ï‡∏±‡∏™‡∏™‡∏∞ ‡∏†‡∏∞‡∏Ñ‡∏∞‡∏ß‡∏∞‡πÇ‡∏ï ‡∏≠...       neg\n",
       "1     üîÆ‡∏Ñ‡∏≤‡∏ñ‡∏≤‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏ö‡∏ú‡πà‡∏≤‡∏ôüîÆ\\n‡∏ï‡∏±‡πâ‡∏á ‡∏ô‡∏∞‡πÇ‡∏° ‡∏ï‡∏±‡∏™‡∏™‡∏∞ ‡∏†‡∏∞‡∏Ñ‡∏∞‡∏ß‡∏∞‡πÇ‡∏ï ‡∏≠...       neg\n",
       "2     üí°‡∏£‡∏≤‡∏®‡∏µ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏î‡∏ß‡∏á‡∏à‡∏∞‡∏™‡∏°‡∏´‡∏ß‡∏±‡∏á‡πÉ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏Åüí°\\n‚úÖ‡∏û‡∏§‡∏©‡∏†\\n‚úÖ‡∏°‡∏±‡∏á‡∏Å‡∏£...       neg\n",
       "3     ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏Ñ‡πà‡∏∞ #‡∏î‡∏π‡πÑ‡∏û‡πà‡∏Å‡∏±‡∏öoctsy\\n\\n‡∏£‡∏µ‡∏ß‡∏¥‡∏ß ‡∏î‡∏π‡∏î‡∏ß‡∏á‡πÑ‡∏û‡πà üôè\\n\\...       pos\n",
       "4     ‡∏Ñ‡∏¥‡∏ß‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏±‡∏Å DM ‡πÄ‡∏•‡∏¢   \\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡∏∞32‡∏ø\\nü•π‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏â‡∏û‡∏≤...       neg\n",
       "...                                                 ...       ...\n",
       "6311  ‡∏ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏ß‡∏¥‡∏ó ‡∏Ñ‡∏∫‡∏ì‡∏¥‡∏ï ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ \\n 50+/100   ‡πÅ...       neg\n",
       "6312  ‡∏ß‡∏¥‡∏ó‡∏¢‡πå‡∏Å‡∏±‡∏ö‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ50+ ‡πÅ‡∏à‡∏Å50/1 ‡∏Ñ‡∏ô ‡∏£‡∏µ‡∏¢‡∏≤‡∏ß‡πÜ55 #O...       neg\n",
       "6313  ‡∏ó‡∏∏‡∏Å‡∏ß‡∏¥‡∏ä‡∏≤50++ ‡πÅ‡∏à‡∏Å 50‡∏ö./1 ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©/‡πÑ‡∏ó‡∏¢ 80++ ‡πÅ‡∏à‡∏Å‡∏≠‡∏µ‡∏Å ...       pos\n",
       "6314                      ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÑ‡∏î‡πâ50+++ ‡πÅ‡∏à‡∏Å100 #Onet66       pos\n",
       "6315  &gt;&gt; ‡∏î‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 13 ‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå 2566 &lt;&lt;...       neg\n",
       "\n",
       "[6316 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display,HTML\n",
    "\n",
    "df = TweetsCounter.tweets_sentiment_analyzer(keyword=\"#Onet66\",fromTime=\"2023.2.12.00.00.00\",toTime=\"2024.2.13.11.00.00\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg    4001\n",
      "pos    2315\n",
      "Name: sentiment, dtype: int64\n",
      "neg    63.347055\n",
      "pos    36.652945\n",
      "Name: sentiment, dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "hovertemplate": "index=%{label}<br>value=%{value}<extra></extra>",
         "labels": [
          "neg",
          "pos"
         ],
         "legendgroup": "",
         "name": "",
         "showlegend": true,
         "type": "pie",
         "values": [
          63.347055098163395,
          36.652944901836605
         ]
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Sentiment Percentage"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Count the number of occurrences of each sentiment\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "\n",
    "print(sentiment_counts)\n",
    "# Calculate the percentage of each sentiment\n",
    "sentiment_percentages = sentiment_counts / len(df) * 100\n",
    "print(sentiment_percentages)\n",
    "# Create the pie chart\n",
    "fig = px.pie(sentiment_percentages, values=sentiment_percentages.values, \n",
    "             names=sentiment_percentages.index, title='Sentiment Percentage')\n",
    "\n",
    "# Show the chart\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly-express\n",
      "  Downloading plotly_express-0.4.1-py2.py3-none-any.whl (2.9 kB)\n",
      "Requirement already satisfied: pandas>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from plotly-express) (1.5.2)\n",
      "Requirement already satisfied: plotly>=4.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from plotly-express) (5.13.0)\n",
      "Collecting statsmodels>=0.9.0\n",
      "  Downloading statsmodels-0.13.5-cp311-cp311-macosx_11_0_arm64.whl (9.2 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from plotly-express) (1.9.3)\n",
      "Collecting patsy>=0.5\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m233.8/233.8 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from plotly-express) (1.24.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/lysist-mac/Library/Python/3.11/lib/python/site-packages (from pandas>=0.20.0->plotly-express) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=0.20.0->plotly-express) (2022.7)\n",
      "Requirement already satisfied: six in /Users/lysist-mac/Library/Python/3.11/lib/python/site-packages (from patsy>=0.5->plotly-express) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from plotly>=4.1.0->plotly-express) (8.2.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/lysist-mac/Library/Python/3.11/lib/python/site-packages (from statsmodels>=0.9.0->plotly-express) (22.0)\n",
      "Installing collected packages: patsy, statsmodels, plotly-express\n",
      "Successfully installed patsy-0.5.3 plotly-express-0.4.1 statsmodels-0.13.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly-express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TweetsCounter.tweets_sentiment_analyzer(\"#‡πÉ‡∏™‡πà‡∏ô‡∏±‡∏ß‡πÅ‡∏ü‡∏°‡∏¥‡∏•‡∏µ‡πà\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"general-amy.csv\")\n",
    "print(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import emoji\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "\n",
    "def removeSpecialChar(text):\n",
    "    return re.sub(r\"[\\]\\[!-@#$?%+:\\\"\\n^_‚Äò‚Äô‚Äú‚Äù]\", \"\", text).rstrip()\n",
    "\n",
    "def removeEmoji(text):\n",
    "    allchars = [str for str in text]\n",
    "    emoji_list = [c for c in allchars if c in emoji.EMOJI_DATA]\n",
    "    return ''.join([str for str in allchars if not any(i in str for i in emoji_list)]).rstrip()\n",
    "\n",
    "def removeLink(text):\n",
    "    new_text = re.sub(r'https?:\\/\\/[^\\s]+', '', text)\n",
    "    # text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE).rstrip()\n",
    "    link_regex = r\"(https?:\\/\\/[-a-zA-Z0-9@:%._\\+~#=]+)\"\n",
    "    return re.sub(link_regex, '', new_text).rstrip().lstrip()\n",
    "\n",
    "# Pre-processing the data\n",
    "def preprocess_train_text(text):\n",
    "    text = removeLink(text)\n",
    "    text = removeEmoji(text)\n",
    "    text = removeSpecialChar(text)\n",
    "    tokens = word_tokenize(text, engine=\"newmm\")\n",
    "    result = [word for word in tokens if word not in list(\n",
    "            thai_stopwords()) and \" \" not in word]\n",
    "    return \" \".join(result).rstrip()\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(preprocess_train_text)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['sentiment']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train the model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate the model on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#Use the model to make predictions on new data\n",
    "new_text = ['''‡πÄ‡∏£‡∏≤‡∏ä‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡πâ‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏±‡∏á ü•π Cr ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡πÄ‡∏û‡∏à IHaveCPU #hrk #heartrocker #‡πÉ‡∏™‡πà‡∏ô‡∏±‡∏ß‡πÅ‡∏ü‡∏°‡∏¥‡∏•‡∏µ‡πà https://t.co/7QHIs4fYsd''']\n",
    "new_text = vectorizer.transform(new_text)\n",
    "new_pred = model.predict(new_text)\n",
    "print(\"Sentiment:\", new_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "from dotenv import load_dotenv\n",
    "from dateutil import tz\n",
    "import tweepy\n",
    "\n",
    "API_KEY = \"SnxucIPt1fg7UUyVOT0T5j0pR\"\n",
    "API_KEY_SECRET = \"yaToQPv95OA1fiNTHD8drKM8g8rZGM7jSQnPOLoxU3QA9UpaLm\"\n",
    "ACCESS_TOKEN = \"1722424471-Xb0DjPVOqXsLj2sXEYXmU2sqxaDC4B793erGO6J\"\n",
    "ACCESS_TOKEN_SECRET = \"D2LyXN11zAoZB0M476eb1ZGDM55oRvy4tBWNb8pR4CO0h\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(API_KEY, API_KEY_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "count = 0\n",
    "def getHashtag(entity_hashtag):\n",
    "        hashtag = \"\"\n",
    "        for i in range(0, len(entity_hashtag)):\n",
    "            hashtag = hashtag + \"#\"+entity_hashtag[i][\"text\"]\n",
    "        return hashtag\n",
    "def createDictData(tweet_author, tweet_create_at, hashtag, keyword, text):\n",
    "        tweet = {}\n",
    "        tweet[\"tweet_author\"] = tweet_author\n",
    "        tweet[\"tweet_create_at\"] = tweet_create_at\n",
    "        tweet[\"hashtag\"] = hashtag\n",
    "        tweet[\"keyword\"] = keyword\n",
    "        tweet[\"text\"] = text\n",
    "        return tweet\n",
    "amount = 10\n",
    "query = \"#Valorant\"\n",
    "for tweet in tqdm(tweepy.Cursor(api.search_tweets, q=query, count=100,\n",
    "                                        result_type=\"recent\", tweet_mode='extended').items()):\n",
    "    entity_hashtag = tweet.entities.get('hashtags')\n",
    "    hashtag = getHashtag(entity_hashtag)\n",
    "    tweet_author = tweet.user.screen_name\n",
    "    keyword = query\n",
    "    dt_str = str(tweet.created_at)\n",
    "    format = \"%Y-%m-%d %H:%M:%S%z\"\n",
    "    dt_utc = datetime.strptime(dt_str, format)\n",
    "    local_zone = tz.tzlocal()\n",
    "    dt_local = dt_utc.astimezone(local_zone)\n",
    "    tweet_create_at = dt_local\n",
    "    try:\n",
    "        text = tweet.retweeted_status.full_text\n",
    "    except:\n",
    "        text = tweet.full_text\n",
    "    user = tweet.user\n",
    "    location = user.location\n",
    "    print(user.screen_name,location)\n",
    "    count += 1\n",
    "    if count == amount:\n",
    "        count = 0\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
